%% grundlagen.tex
%% $Id: grundlagen.tex 28 2007-01-18 16:31:32Z bless $
%%

\chapter{Grundlagen \& aktuelle Forschung}
\label{ch:Basics}

\section{Schlafmedizin}
\label{ch:Basics:se:schlafmedizin}
% start seite 3-5 im buch schlafmedizin_1x1 
Unter dem Begriff \textit{Schlafmedizin} versteht man die Lehre von Diagnostik, Klassifikation und Behandlung von Störungen während des Schlafs \cite{croenleinSchlafmedizin1x1Praxisorientiertes2017}. 
Trotz Er"-wäh"-nung"-en in der Antike gewinnt Schlafmedizin erst seit dem letzten Jahrhundert an Bedeutung.
Mithilfe der Polysomnographie konnten unterschiedliche Schlafphasen zyklischen Ablaufs erkannt werden.
Zudem konnten den Schlafphasen physiologische Eigenschaften nachgewiesen werden.
Heutzutage sind ca. 80 Schlafstörungen in dieversen Bereichen bekannt, welche neben psychologischen Testverfahren überwiegend elektrophysiologisch untersucht und behandelt werden.
Patienten werden mit ambulanten Hilfsmitteln oder stationär in einem Schlaflabor untersucht und diese dabei ermittelten Daten werden anschließend von technisch ausgebildetem Personal analysiert.

In einem Schlaflabor wird eine Polysomnographie durchgeführt, womit genauere Messergebnisse im Vergleich zu ambulanten Hilfsmitteln (z.B einer Langzeitbewegungsmessung) erreicht werden können.
Während einer Polysomnographie werden Gehirnströme, Augenbewegungen und Muskelspannungen erkannt, wodurch die einzelnen Schlafphasen unterschieden werden können.
Die verschiedenen Sensorwerte werden dann in Form eines Hypnogramms mittels der Kriterien des AASM (engl. \textit{American Association for Sleep Medicine}) ausgewertet (siehe Abbildung \ref{hypnogram_example}). 
Hierbei werden die Schlafstadien in \textit{Wachphase (w)}, \textit{Einschlafen (N1)}, \textit{leichten Schlaf (N2)}, \textit{Tiefschlaf (N3)} und \textit{Rapid-Eye-Movement-Schlaf (REM)} unterteilt.

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.33]{respiration/hypnogram_example}
    \caption{Beispielaufzeichnung, dargestellt in einem Hypnogramm \cite{stuckPraxisSchlafmedizinDiagnostik2018}}
    \label{hypnogram_example}
\end{figure}

% ende cite
% start seite 9- im buch schlafmedizin_1x1 
Im Schlaflabor werden zudem auch Untersuchungen der Müdigkeit, der Tagesschläfrigkeit und der Aufmerksamkeit vorgenommen \cite{croenleinSchlafmedizin1x1Praxisorientiertes2017}.

Atmungsstörungen können oft die Ursache von Schlaganfällen, Herzinfarkten oder den eben genannten Symptomen sein, welche zu erheblichen psychischen Störungen führen können.
% ende cite
Aus diesem Grund ist es wichtig, so genau wie möglich Schlafstörungen bestimmen zu können, um Folgeerkrankungen zu verhindern. 

\section{Klassifizierung von Schlafstörungen}
\label{ch:Basics:se:classification}
Zur Charakterisierung von Schlafstörungen werden viele Biosignale während des Schlafs registriert, die entscheidene Merkmale liefern \cite{stuckPraxisSchlafmedizinDiagnostik2018}.
Aufgrund dieser Annahme wurde eine Einteilung in 7 Klassifikatoren für Schlafstörungen entwickelt:
\begin{itemize}
    \item Ein- und Durchschlafstörungen (Insomnien)
    \item schlafbezogene Atmungsstörungen
    \item Hypersomnien zentralnervösen Ursprungs
    \item zirkadiane Rhythmusschlafwachstörungen
    \item Störungen in Verbindung mit Schlaf, Schlafstadien oder partiellem Erwachen (Parasomnien)
    \item schlafbezogene Bewegungsstörungen
    \item andere Schlafstörungen
\end{itemize}

Diese Gliederung orientiert sich an der \textit{ICSD-3} \cite{stuckPraxisSchlafmedizinDiagnostik2018}.


Diese Bachelorarbeit ist darauf fokussiert, eine zentrale Schlafapnoe zu klassifizieren, die Bestandteil der {\glqq schlafbezogenen Atmungsstörungen\grqq} ist.
Neben der zentralen Apnoe gibt es die obstruktive Apnoe. 
Hierbei sind die Atemwege geschlossen und eine Atmung ist für mehrere Sekunden unmöglich.
Circa 20\% aller Erwachsenen haben fünf oder mehr obstruktive Ereignisse pro Schlafstunde \cite{croenleinSchlafmedizin1x1Praxisorientiertes2017}.
Zentrale Apnoe hingegen tritt seltener auf als obstruktive Apnoe, jedoch auffällig oft bei besonderen Patientengruppen. 
Ein Beispiel liefern Patienten mit Herzinsuffizienzen und einer eingeschränkten kardialen Pumpfunktion.
Unter einer zentralen Schlafapnoe leiden 72\% dieser Patientengruppe. 
Dies macht die Bedeutung der Klassifikation deutlich, da eine genaue Erkennung einer zentralen Apnoe hier sehr wichtig ist.

\subsection{Zentrale Schlafapnoe}
\label{ch:Basics:se:apnoe}
Bei der zentralen Apnoe steht der Luftfluss trotz offener Atemwege für mindestens $10\si{\s}$ still. 
Dies kann vollständig (zentrale Apnoe) oder partiell (zentrale Hypopnoe) erfolgen. 
Ab einer Anzahl von fünf Apnoeereignissen wird zentrale Apnoe diagnostiziert.
Die Ursachen gelten hierbei als internistische oder neurologische Grundlage.
Typische an- und abschwellige Muster sind auf eine chronische Herzinsuffizienz, auf eine verlängerte Kreislaufzeit oder durch eine zentralnervöse Verstellung der sogenannten Apnoeschwelle zurückzuführen.
Der $CO_2$-Gehalt im Blut wird als Apnoeschwelle bezeichnet.
Am Tag sind die Symptome der zentralen Apnoe eher an deren Ursache, den internistischen und neurologischen Grunderkrankungen, zu erkennen, da diese häufig nicht von den Symptomen der Schlafapnoe zu unterscheiden sind. 
In der Nacht wird zentrale Apnoe ebenso wie obstruktive Apnoe in Form von Atem"-aus"-set"-zern häufig vom Partner des Patienten beobachtet.
Zudem kann lautes und unregelmäßiges Schnarchen ein Indiz für eine Apnoe sein, ebenso wie ein Aufwachen in Atemnot.

Eine Schlafapnoe kann jedoch in unterschiedlichen Schweregraden auftreten. 
Es gibt Patienten, welche kaum bis keine Probleme haben und nur aufgrund von nächtlichen Erkenntnissen ihrer Partner zum Arzt geschickt werden. 
Es gibt jedoch auch Patienten, die am Tag Probleme haben, bei monotonen Situationen wach zu bleiben.

Eine Diagnose würde mögliche Folgeerkrankungen schneller erkennbar machen und die Ursache dieser erklären.

\section{Maschinelle Lernverfahren}
\label{ch:Basics:se:ml}
Zur Klassifikation einer zentralen Apnoe werden im Rahmen dieser Bachelorarbeit verschiedene Klassifikationsverfahren verwendet, welche dann zentrale Apnoeereignisse anhand der gesammelten Trainingsdaten klassifizieren sollen.

Maschinelle Lernverfahren sind Algorithmen, welche ihre Performance mittels Trainingsdaten verbessern \cite{neumannMaschineLearningKIT2020}. 
Es wird zwischen folgenden Lernverfahren unterschieden:
\begin{itemize}
    \item Supervised Learning
    \item Unsupervised Learning
    \item Reinforcement Learning
\end{itemize}
Beim \textit{Supervised Learning} sind die Trainingsdaten im Vergleich zum \textit{Unsupervised Learning} markiert.
Das heißt, dass zu jedem Eintrag ein Bit gespeichert wird, welches angibt, ob eine Apnoe zu dem Zeitpunkt stattfand, oder nicht. 
Falls ein Apnoeereignis simuliert wurde, wird eine $1$ ({\glqq positiv markiert\grqq}) eingetragen, andernfalls eine $0$ ({\glqq negativ markiert\grqq}).
Die folgenden Tabelle zeigt die verschiedenen Modelle bei \textit{Supervised} und \textit{Unsupervised Learning}:
\begin{center}
    \begin{tabular}{ | l | l | }
      \hline
      \textbf{Supervised Learning} & \textbf{Unsupervised Learning} \\ \hline
      \hline
      Regression & Clustering \\ \hline
      Klassifikation & Dimensionsreduktion \\
      \hline
    \end{tabular}
\end{center}

Jeder Algorithmus, welcher in einem dieser Modelle des maschinellen Lernverfahrens eingesetzt wird, besteht aus 3 Teilen: Zum einen der \textit{Representation}, der \textit{Evaluation} und der \textit{Optimization}. 
In der \textit{Representation} unterscheidet man nach dem zugrunde liegenden Modell, welches beispielsweise ein Entscheidungsbaum, ein neuronales Netz oder eine Support-Vektor-Maschine sein kann.
Die \textit{Evaluation} behandelt die Frage, in welche Richtung die Entscheidung getroffen werden soll. 
Beispiele hierfür wären die Genauigkeit, der Precision \& Recall, die Entropie oder der Likelihood-Schätzer.
Beim dritten Teil, der \textit{Optimization}, wird eine Optimierung des Algorithmus angestrebt. 
Dies kann unter anderem mit Methoden zweiter Ordnung, zufälliger Suche, einem absteigenden Gradienten oder der Methode der kleinsten Quadrate versucht werden.

Das in dieser Bachelorarbeit verwendete Lernverfahren ist \textit{Supervised Learning} mit dem zugehörigen Modell \textit{Klassifikation}.
Aus dem Datensatz werden Features berechnet, welche dann ein wichtiger Teil der Klassifikation sind.
Ein Feature ist ein Merkmal eines Datensatzes, welches ein individuelles, messbares Attribut der Rohdaten ist.
Pro Klassifikation werden üblicherweise eine Vielzahl an Features gesammelt, anhand derer der Klassifikator seine Entscheidungen trifft.

Zur Evaluation wurden verschiedene Klassifkationsverfahren verwendet, welche im Folgenden genauer erläutert werden.

\subsection{Random Forest}
\label{ch:Basics:se:ml:ss:randomForest}

Random Forest ist ein Klassifikationsverfahren des \textit{Supervised Learning} \cite{WaybackMachine2016}. 
Zur Klassifikation werden markierte Daten vorausgesetzt, woraus eine gelernt mathematische Repräsentation erstellt wird (\textit{model}). 
Dieses Modell wird anschließend genutzt, um auf unmarkierten Daten eine Vorhersage zu treffen.
Random Forest basiert auf Entscheidungsbäumen. 
Das sind Bäume, bei welchen pro Ast eine Entscheidung getroffen wird.
Sie lernen binäre Entscheidungsregeln, die einer logischen Abfolge entsprechen.
Jedoch sind einzelne Entscheidungsbäume nicht robust genug und neigen zu Overfitting.
Random Forest nutzt deshalb viele Entscheidungsbäume und trainiert diese auf dem selben Trainingsdatensatz. 
Der Zusammenschluss der Entscheidungen jedes Entscheidungsbaums repräsentiert die endgültige Entscheidung.
Bei Random Forest werden bei jeder Verästelung eine zufällige Teilmenge der Features in Betracht gezogen, was den Einfluss von stark korrellierenden Features verringern soll.

Entscheidungsbäume können allgemein durch verschiedene Arten zusammengetragen werden. 
Zum einen ist dies mit \textit{Bagging}, zum anderen mit \textit{Boosting} möglich.
Bei \textit{Bagging} werden zufällige Stichproben aus der Datenmenge für jeden Entscheidungsbaum genommen \cite{jamesIntroductionStatisticalLearning2013}.
Je nach Wahl geschieht dies mit oder ohne Zurücklegen dieser zufälligen Teilmenge für den nächsten Entscheidungsbaum.
Bei Bagging werden die Entscheidungsbäume parallel trainiert, was sich positiv auf die Performance auswirkt.
Bei \textit{Boosting} werden ebenfalls Teilmengen pro Entscheidungsbaum aus der Datenmenge gepickt, jedoch nicht gleichverteilt. 
Es werden schwierige Fälle höher gewichtet, wodurch diese häufiger in einen Entscheidungsbaum mit aufgenommen werden. 
Somit werden die darauffolgenden Entscheidungsbäume mit Zurücklegen der Teilmenge ausgewählt.
Falls eine falsche Vorhersage auf einen Datenbestand getroffen wurde, erhöht sich die Gewichtung.
Die Wahrscheinlichkeit ist nun höher, dass dieser Datenbestand im nächsten Entscheidungsbaum enthalten ist.
Die Entscheidungsbäume werden bei \textit{Boosting} sequenziell trainiert.

Random Forest verwendet \textit{Bagging}. 
Die endgültige Entscheidung ist entweder ein Mehrheitsvotum oder der Durchschnitt der Vorhersagen aller Trainingsläufe.
Bei Random Forest können zusätzlich einige Hyperparameter modifiziert werden, wie unter anderem die Anzahl der zu kombinierenden Entscheidungsbäume, die maximale Baumtiefe oder die maximalen Features pro Verästelung. 
Die Vorteile von Random Forest sind die Schnelligkeit, die Flexibilität und die Parallelisierbarkeit.
Zudem gibt das Resultat nicht nur die entgültige Entscheidung, sondern auch die Wahrscheinlichkeit der Entscheidung an.
Zu den Nachteilen zählt die schlechte Performance bei seltenen Klassen und die Anfälligkeit für Overfitting.
Des Weiteren ist Random Forest ein Blackbox Modell, wodurch es kaum möglich ist, zu ermitteln, wie die Entscheidung getroffen wurde.

\subsection{XGBoost}
\label{ch:Basics:se:ml:ss:xgboost}
Vor der Erklärung von XGboost muss zuvor \textit{Gradient Boosting} eingeführt werden.
Gradient Boosting ist wie Random Forest ein Teil des überwachten Lernens (\textit{Supervised Learning}) und kann für die Klassifikation oder Regression verwendet werden \cite{friedmannStochasticGradientBoosting1999}. 
Zudem ist Gradient Boosting wie Random Forest ein Ensemble-Learner, d.h. sie setzen sich aus vielen einzelnen Modellen (den Entscheidungsbäumen) zusammen.
Im Gegensatz zu Random Forest verwendet Gradient Boosting nicht \textit{Bagging}, sondern \textit{Boosting}.
Wie schon im Abschnitt \ref{ch:Basics:se:ml:ss:randomForest} eingeführt, trainiert \textit{Boosting} zufällig gewichtete Stichproben aus einer Datenmenge mit Zurücklegen. 
Falsche Entscheidungen erhöhen die Gewichtung, richtige Entscheidungen verringern die Gewichtung jeder Vorhersage. 
Somit werden schwierige Fälle besonders beachtet, da die Anpassung der Gewichtungen nach jeder Vorhersage stattfindet, insbesondere bevor die neue Teilmenge anhand der Gewichtung bestimmt wird.
Das Trainieren auf Teilmengen wird auch als stochastisches Gradient Boosting bezeichnet und verringert die Wahrscheinlichkeit für Overfitting.
Zudem wird eine bessere Generalisierbarkeit erreicht.

Zu Beginn wird ein Basismodell bestehend aus den Entscheidungsbäumen gewählt, worauf anschließend Vorhersagen anhand der Trainingsdaten getroffen werden. \\
Daraufhin werden die Gewichte je nach der getroffenen Vorhersage angepasst.
Aus dem Basismodell mit den nun angepassten Gewichten wird eine Teilmenge gewählt, womit erneut Entscheidungsbäume entstehen und Vorhersagen getroffen werden können.
Bei Gradient Boosting wird nun mittels Gradienten der Fehler der verschiedenen Ensembles minimiert.
Auch hier gibt es Hyperparameter, welche angepasst werden können. 
Diese sind sehr ähnlich zu Random Forest, werden jedoch um weitere Parameter ergänzt, wie zum Beispiel einer Funktion, welche den Fehler berechnet, die Anzahl der Iterationen pro Baum oder auch die Anzahl der Instanzen pro Blatt.

XGBoost ist nun eine spezielle Version des Gradient Boosting, und zwar das \textit{Extreme Gradient Boosting} \cite{chenXGBoostScalableTree2016}.
Der Unterschied zu Gradient Boosting ist hierbei, dass bei der Fehlerfunktion (Loss-Funktion) die Gradienten 2. Ordnung gewählt werden, wodurch mehr Informationen für die Verringerung des Fehlers bereit stehen.
Zudem können dadurch die besten Entscheidungsbäume approximiert werden. 
XGBoost verwendet außerdem L1 \& L2 Regularisierung, dadurch kann besser generalisiert werden und Overfitting vermieden werden.
XGBoost ist parallelisierbar, schnell und kann zudem für verteiltes Trainieren auf Clustern betrieben werden.

\subsection{Support Vektor Maschine (SVM)}
\label{ch:Basics:se:ml:ss:svm}
Eine Support Vektor Maschine ist ein Klassifikationsverfahren für Probleme, welche in zwei Klassen gruppiert werden \cite{cortesSupportvectorNetworks1995}.
Bei der linearen Support Vektor Maschine wird nun eine lineare {\glqq Trennlinie\grqq} gesucht, welche die Menge der Daten in zwei Klassen gruppiert. 
Diese Trennlinie wird optimiert.
Es gibt auch eine nichtlineare SVM, die eine nichtlineare Trennlinie sucht.
Hierbei kann es jedoch zu Overfitting kommen, da eine nichtlineare Trennlinie durch potenzielle Outlier sehr komplex werden kann und zu {\glqq gut\grqq} optimiert wird.
Jeder Wert im Datensatz ist ein Support Vektor und somit ein repräsentativer Punkt, welcher bei der Klassifikation gruppiert werden soll.
Die Trennlinie muss also zwischen allen markierten Daten unterscheiden können.
Jedoch ist die Komplexität hierbei sehr hoch, da eine Trennlinie beziehungsweise eine Trennebene im hochdimensionalen Raum, nur mit sehr hohem Aufwand gefunden werden kann.
Die Suche nach der Trennline kann mit unterschiedlichen Kernel bestimmt werden.
Die beliebtesten Kerneltypen sind:

\begin{center}
    \begin{tabular}{ | l | l | }
        \hline
        Kernel Name & Kernel Funktion \\ \hline
        Linear Kernel & $K(x)=x \cdot y$ \\ 
        Polynomial Kernel & $K(x)=(x\cdot y+1)^d$ \\
        Radial Basis Function (RBF) Kernel & $K(x)=e^{-\gamma(\Vert x-y \Vert)^2}$ \\
        \hline
    \end{tabular}
\end{center}

Die korrekte Wahl des richtigen Kernels ist entscheidend für deren Performance und Genauigkeit, jedoch nicht sehr einfach.
Ein Vorteil von SVM ist die Effektivität im hochdimensionalen Raum.
Des Weiteren ist SVM speichereffizient und zudem können durch die verschiedenen Kerneltypen mehrere Datensätze variabler verarbeitet werden.
Zu den Nachteilen zählt, dass die Performance schlecht ist, wenn die Anzahl der Features größer als die Anzahl der Samples ist. 
Zudem neigt SVM gerade im nichtlinearen Bereich schnell zu Overfitting.

\section{Forschung von Klassifikation anhand von IMU-Daten}
Es gibt bereits Ansätze, welche sich damit befassen, Alternativen zur Ermittlung von Schlafstörungen zu finden. 
Somit könnte ein Besuch im Schlaflabor durch einen bequemen Test ersetzt werden. 
Ein vielversprechender Ansatz ist es, mittels IMU-Daten die Bewegung des Körpers zu messen und anhand dieser Informationen unter anderem die Atmung herauszufiltern, um dann Rückschlüsse auf Schlafstörungen ziehen zu können.

\subsection{Beschleunigungssensor am Brustkorb}
Bereits 2018 gab es Forschung in diesem Bereich. \textit{Phan Duy Hung} hat sich damit befasst, einen Beschleunigungssensor (\textit{Accelerometer}) an den Brustkorb zu fixieren \cite{hungCentralSleepApnea2018}.
Durch die Platzierung an genau dieser Stelle wurde der Herzschlag genauer erkannt. 
Die Rohdaten zeigen hierbei bereits die Herzfrequenz und die Atmung des Probanden (siehe Abb. \ref{imu_research_hung_rawData}). 

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\textwidth]{imu_research/Paper_Hung_rawData}
    \caption{Rohdaten des Accelerometers in \cite{hungCentralSleepApnea2018}}
    \label{imu_research_hung_rawData}
\end{figure}

Die Daten wurden nach der Aufzeichnung durch einen Bandpassfilter mit adaptiver Apassung optimiert, um die SNR (\textit{signal-noise-ratio}) zu verringern.
Der Puls wurde ermittelt, indem Peaks (Max: \textit{V}-Peak, Min: \textit{R}-Peak) gefunden und als Herzschlag interpretiert wurden.
Des Weiteren musste Signalrauschen, beispielsweise von der Reibung des T-Shirts und der Haut, aus dem Signal herausgefiltert werden. 
Zudem wurden 3 Features anhand der Amplitude über die Zeit berechnet. 
Das erste Feature ist das \textit{Spektralverhältnis (spectral ratio)}. 
Hier wird ein Leistungsspektrum eines einminütigen Segments vom HR-Signal geschätzt. 
Der Frequenzbereich zwischen $[0,1]\si{\hertz}$ wurde untersucht. 
Dieser Bereich spiegelt die Frequenzvariation zwischen zentraler Schlafapnoe und normaler Aktivität wieder.

Im Bereich von $[0.3,0.6]\si{\hertz}$ zeigt sich das Maximum der spektralen Leistung.
Dieser Wert wird normiert, indem er durch den Mittelwert der spektralen Leistung im Bereich $[0.1,0.3]\si{\hertz}$ geteilt wird. 
Das Verhältnis von $\max(P)$ im Bereich von $[0.3,0.6]\si{\hertz}$ zum Mittelwert($P$) in $[0.1,0.3]\si{\hertz}$ ist unabhängig von der Person $P$.

Das zweite Feature sind die \textit{Wavelet- Koeffizienten (wavelet coefficients)}, bei welchen für die Analyse mit mehreren Auflösungen und guter Lokalisierungsfähigkeit im Zeit-Frequenz-Bereich häufig eine Wavelet-Transformation verwendet wird. 
Hierbei wird das Atemsignal in 5 Ebenen mit der db2-Wavelet zerlegt. Danach werden die Standardabweichungen der Detailkoeffizienten in den Ebenen 4 und 5 verwendet. 

Das dritte Feature sind die \textit{linear prediction coefficients}. 
Die lineare Vorhersage zweiter Ordnung
\begin{center}
    $x(n) = a_1 x(n-1) + a_2 x(n-2) + e(n)$
\end{center} 
wird verwendet, wobei $x$ eine Zeitreihe (\textit{Timeseries}) ist, $e(n)$ der Vorhersagefehler und {a1, a2} die Vorhersagekoeffizienten, die durch die Kleinste-Quadrate-Methode zu bestimmen sind.

Nach einer Varianzanalyse (\textit{ANOVA}) werden die folgenden Werte ausgewählt: \\
ANOVA: $a_1$, $a_2$ und $\sqrt{a_1^{2} + a_2^{2}}$.


Zudem wurden nichtlineare Features in Betracht gezogen, da bereits vorher festgestellt wurde, dass in komplexen Atemuntersuchungen lineare Funktionen nicht ausreichen. Die Herzfrequenz wurde hierbei als Zeitreihe (\textit{Timeseries}) betrachtet.
Es wurden diesbezüglich die nichtfunktionalen Features der \textit{Poincaré-Plots (Poincare plot geometry)}, \textit{trendbereinigende Fluktuationsanalyse (Detrended Fluctuation Analysis)}, \textit{ungefähre Entropie (Approximate Entropy)} sowie der \textit{Ljapunow-Exponent (Largest Lyapunov exponent)} verarbeitet. 

Die Features wurden anschließend mit der \textit{ANOVA-Toolbox} ausgewertet.
Somit konnte ermittelt werden, ob in dem zeitlichen Intervall eine Apnoe stattgefunden hat, oder nicht.

Durch dieses Paper wurde eine Genauigkeit von 84.2\% erreicht, eine zentrale Apnoe als solche zu erkennen.
Zudem wurde zu 84.1\% erkannt, dass in diesem Zeitrahmen keine zentrale Apnoe vorkam.


\subsection{Detektion direkt am Kopf mittels der Google-Glass Brille}
Bereits 2015 wurde versucht, durch Informationen des Google-Glass den Puls und das Atemsignal zu ermitteln \cite{hernandezCardiacRespiratoryParameter}. 
Der Vorteil hierbei ist die Position der Brille. 
Da sie am Kopf platziert ist, liefert die Brille andere Werte im Vergleich zu IMU-Daten, die am Brustkorb aufgezeichnet werden.
In Abbildung \ref{imu_research_google_glass} ist die Google-Glass Brille zu sehen.
Der Gyroskop- und Beschleunigungssensor ist an der rechten Seite angebracht, ebenso wie eine Kamera, ein Magnetometer, ein Lightsensor und ein Mikrofon. 
Obwohl die Google-Glass Brille nicht entwickelt wurde, um physiologische Daten zu sammeln, kann sie dafür verwendet werden, da alle nötigen Sensoren darin verbaut sind.
Die Resultate liefern einen mittleren absoluten Fehler (\textit{MAE}) von 0.82 Schlägen pro Minute (STD: 1.98) der Herzrate und 0.6 Atmungen pro Minute (STD: 1.19) bei der Atmung unter Betrachtung verschiedener Beobachtungsfenster und Kombinationen der Sensoren. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth / 2]{imu_research/googleGlass}
    \caption{Darstellung der Google-Glass Brille: Die Brille hat einen Magnetometer, einen Gyroskop- und Beschleunigungssensor, eine Kamera, ein Mikofon und einen Lichtsensor verbaut. Diese Sensoren werden genutzt, um die Atmung und den Puls zu ermitteln. \cite{hernandezCardiacRespiratoryParameter}}
    \label{imu_research_google_glass}
\end{figure}
Die Herausforderung bestand zudem darin, stromsparende Echtzeitberechnungen mit Algorithmen zu entwickeln, womit physiologische Parameter extrahiert wurden. Der Nutzer soll das Gerät im Alltag normal weiternutzen können. 

Es wurden 2 Techniken entwickelt, eine zur Ermittlung des Pulssignals, die andere für das Atemsignal.
\subsubsection{Pulssignal}
Die Schätzung des Pulssignals wurde anhand einer Zeitreihe (\textit{Timeseries}) von Vektoren in mehrere Schritte aufgeteilt:
\begin{itemize}
    \item Von jeder Dimension des Vektors wurde ein gleitendes Durchschnittsfenster von 3 Abtastwerten subtrahiert, wodurch Signalverschiebungen und Trends entfernt werden konnten.
    \item Ein Bandpass Butterworthfilter der 4. Ordnung mit den Cut-Off Frequenzen von $10 \si{\hertz}$ und $13 \si{\hertz}$ wurde auf jede Dimension angewandt, um Veränderungen des BCG (\textit{Ballistokardiogramm}) zu isolieren.
    \item Zudem wurde ein Bandpass Butterworthfilter der 2. Ordnung mit den Cut-Off Frequenzen von $0.75 \si{\hertz}$ und $2.5 \si{\hertz}$ (entspricht 45 and 150 Schlägen pro Minute) angewandt, was schließlich das resultierende Pulssignal liefert.
\end{itemize}

\begin{figure}[ht]
    \centering
    \begin{subfigure}{.49\textwidth}
        \includegraphics[width=\textwidth]{imu_research/googleGlass_pulse_fig2}
      \caption{Beispiel eines Pulssignals mittels der Gyroskopdaten (rot) und des Ground-Truth Sig"-nals (blau). Die beiden unteren Graphen zeigen das Fouriespektrum von jedem Signal (\textit{FFT: Fourier Spectrum, GYR: Gyroscope, BVP: Blood Volume Pulse, HR: Heart Rate, bpms: beats per minute})}
      \label{background:googleGlass:pulse_wave}
    \end{subfigure}
    \begin{subfigure}{.49\textwidth}
        \includegraphics[width=\textwidth]{imu_research/googleGlass_respiratory_fig3}
      \caption{Beispiel einer Schätzung des Atemsignals anhand der Beschleunigungsdaten (blau) und des Ground-Truth-Signals (rot). Die beiden unteren Graphen zeigen das Fourierspektrum jedes Signals. (\textit{FFT: Fourier Spectrum, ACL: accelerometer, RESP: Respiration from chest band, RR: respiration rate, bpms: breaths per minute})}
      \label{background:googleGlass:respiratory_wave}
    \end{subfigure}
    \caption{Herzrate- und Atemfrequenzanalyse}
    \label{background:googleGlass}
  \end{figure}

Die Abbildung \ref{background:googleGlass:pulse_wave} zeigt ein Signal des Herzschlags, gesammelt von den Informationen der Gyroskopdaten. Diese Daten wurden mit der Google-Glass Brille aufgezeichnet, während die Person auf dem Rücken lag. Der obige Graph zeigt ein 3-Achsen Gyroskopsignal über eine Dauer von 5.5 Sekunden. Der mittlere Graph zeigt die Schätzung des Herzschlags, nachdem die vorgestellten Methoden angewandt wurden in rot, die des Referenzsignals in blau. Es ist sehr gut zu erkennen, dass die Schätzung sehr nahe an den Referenzsignalen ist.

\subsubsection{Atemsignal}
Das Atemsignal wurde in mehreren Schritten berechnet:
\begin{itemize}
    \item Ein gleitender Mittelwertfilter wurde auf jede Komponente angewandt. Die Fensterlänge wurde auf die Dauer eines Atemzyklus gesetzt, in diesem Fall 45 Atmungen pro Minute. 
    \item Ein Bandpass Butterworthfilter der 4. Ordnung mit den Cut-Off Frequenzen von $0.13 \si{\hertz}$ und $0.75 \si{\hertz}$ (entspricht 8-45 Atmungen pro Minute) wurde auf jede Dimension angewandt.
    \item Da die verschiedenen Dimensionen der Sensoren nicht in Relation zu den Körperpositionen stehen, wurde eine Principal Component Analyse angewandt, um einen derartigen Einfluss zu reduzieren. Nach einer Fast Fouriertransformation (FFT) auf jede Komponente wurde das Signal mit der Periode mit der maximalen Größe ausgewählt, welche innerhalb des zu betrachtenden Frequenzbereichs liegt.
\end{itemize}

Die Abbildung \ref{background:googleGlass:respiratory_wave} zeigt ein Beispiel einer Atemfrequenzschätzung der Beschleunigungsdaten eines Patienten. Wie zu sehen ist, sind die Daten sehr nahe an dem Referenzwert, welcher als Ground-Truth mit dem Brustgurt mit aufgezeichnet wurde.


\subsection{Überwachung von Puls und Atmung mittels eSense-Earpods}
Im Jahr 2019 wurde von \textit{Tobias Röddiger}, \textit{Daniel Wolffram} und \textit{David Laubenstein} nachgewiesen, dass es möglich ist, mittels den eSense-Earpods die Atmung und den Puls annähernd zu ermitteln \cite{roddigerRespirationRateMonitoring2019}. 
Dies gelang etwas genauer als das Monitoring von \textit{J. Hernandez} mit dem Google Glass \cite{hernandezCardiacRespiratoryParameter}.
Es wurde hierbei eine Studie mit 12 Personen aufgezeichnet, welche in 3 Positionen (liegend, stehend, sitzend) jeweils vor beziehungsweise nach einer sportlichen Bewegungsphase einen einminütigen Atem"-ab"-lauf durchgeführt haben. 
Die Analyse der Daten erfolgte im Anschluss der Studie.
Dabei wurden die Daten in einer Pipeline verarbeitet, welche zuerst das Rauschen reduzierte, anschließend einen Triangle-Filter der Breite $2\si{\s}$ anwendete und danach eine PCA (engl. \textit{principal component analysis}) ausführte, um die Daten unabhängig von deren Achse zu bewerten.
Nun wurden Fenster mit der Größe von $20\si{\s}$ extrahiert, anhand welchen Atmung und Puls berechnet wurde.
Die Resultate ergaben einen mittleren absoluten Fehler (engl. \textit{mean absolute error}) von 2.62 CPM (acc) und 2.55 CPM (gyro), jedoch variierten diese von Proband zu Proband.

Der Ablauf der Analyse begann damit, dass ein gleitendes Durchschnittsfenster (\textit{sliding average window}) von 3 Samples von jeder Dimension abgezogen wurde. 
Zudem wurde auf jeder der Komponenten ein Mittelwertfilter angewandt. 
Diese haben eine Fenstergröße von 2 Sekunden. 
Das soll Signalverschiebungen und Signaltrends entfernen.
Anschließend wurde eine kubische Splineinterpolation auf den Datensatz angewandt, um die Daten aufzublasen.
Falls zuviel Bewegung in einem Fenster zu erkennen ist, wurde das Fenster verworfen \cite{sunSleepMonitorMonitoringRespiratory2017}.
Daraufhin wurde ein Bandpass-Butterworth-Filter der 4. Ordnung auf den Datensatz angewandt, um das Rauschen zu entfernen.
Zum weiteren Glätten der Signale wurde ein Dreiecksfilter angewandt \cite{haotianMindfulWatch2017}, worauf schließlich eine Hauptkomponentenanalyse (PCA) durchgeführt wurde.
Auf jede Hauptkomponente wurde nun eine Spektralanalyse mithilfe einer Fourier"=Transformation (FFT) angewandt. 
Die Frequenz, welche dem Peak mit der höchsten Magnitude entspricht, resultiert schlussendlich als Atemfrequenz.

\begin{figure}[ht]
    \includegraphics[width=1\textwidth]{imu_research/towards_resp_rates_waves}
    \caption{Rohdaten der Beschleunigungs- und Gyroskopdaten innerhalb von $12 \si{\s}$, sowie die Atem- und Pulsschätzung, verglichen mit dem Ground-Truth (blau).}
    \label{background:towards_resp_esense:results}
\end{figure}